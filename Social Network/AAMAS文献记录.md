#### Simulating and Evaluating Generative Modeling and Collaborative Filtering in Complex Social Networks - 模拟和评估复杂社会网络中的生成建模和协同过滤

##### 1.摘要

- 目的：提出了一个**多智能体模拟框架（结合大语言模型、生成式嵌入方法、协同过滤**）来**建模大规模的线上社交网络中的动态**

  - 方法：学习不同的agent-embeddings来捕捉不同用户行为，使用MLP进行用户内容排名

- 比较了以下三种策略

  1. 生成建模方法，集成了agent-embeddings和协同过滤
     - agent-embeddings：将社会网络中的节点表示为向量
     - 推荐系统：帮用户从海量信息中筛选出可能有帮助的内容
     - 常见的推荐方法
       - 基于内容：根据**物品特征**推荐相似的东西
       - 协同过滤：根据**用户和物品的相似性**推荐
       - 二者混合（主流）
  2. 基于LLM方法：依赖上下文
  3. 基于反思的聚类技术

- 评价指标：评论数量、评论树深度、用户参与模式、主题分布

- 结果：第一种方法可以更好的逼近复杂现象

- 框架支持**政策驱动实验**，通过引入**社会正则化器**（如凝聚力、极化、偏见）来模拟不同社交场景

  - 政策主要指**平台策略**或**治理规则**

  > - 推荐算法应该优先展示什么内容？是用户最喜欢的内容，还是能拓宽他们视野的内容？
  > - 为了减少社会撕裂（极化），平台是否应该主动向用户推荐对立观点的文章？
  > - 为了增强社区凝聚力，是否应该更多地推荐小组内的热门内容？
  >
  > 在现实世界中，直接实施这些策略是高风险、高成本的，可能引发用户不满或意想不到的负面后果。

  - 政策驱动实验：可以修改算法的目标（政策），运行模拟，然后观察结果，从而评估该政策的好坏
  - 社会正则化器（目的：模拟出截然不同的社交网络环境）
    - 凝聚力正则化器：鼓励同一社区的用户看到相似内容
    - 极化正则化器：减少整个网络的分裂，鼓励不同群体之间的交流
    - 偏见正则化器：防止用户的信息食谱过于单一

##### 2.引言及背景

- 背景：现在社交生态不行（推荐系统不行） -  搜索相同内容但结果不同的“认知割裂”，同质化群体的“回声室”、平台为了保证商业最大化放大消极面
- 思路：构建基于 LLM 增强智能体的多智能体模拟框架，依托生成式 AI（尤其是 LLMs）模拟在线交互并分析政策影响，采取检索增强生成解决LLM上下文有限的问题

- 了解到大预言模型赋能的agent很好

##### 3.方法内容总结

- 整体逻辑：三大支撑技术 - ①整合工作记+推理与可扩展工具 的**认知架构**；②学习**嵌入分布实现智能体行为生成**的**生成式建模**；③用于协同过滤、复杂分析等任务的**专用神经网络工具**

> 搞明白这三个技术各自的作用

###### ①LLM增强智能体的认知架构（LLM作为agent的大脑）

- 组成：感知层、记忆层、反思与决策层
  - 感知层：主要由LLM组成，LLM接收环境的输入（文字、图像、语音等），将这些数据转换为agent可以理解的“感知”，比如原数据为用户带有积极情绪的评论，LLM会将这些非结构化的评论抽象转换为关于情感的结构化信息，这样agent可以更好的“感知“到用户的积极情绪
  - 记忆层：agent的记忆库，分为短期记忆与长期记忆。短期记忆即LLM的上下文，长期记忆由检索增强技术，agent可以从外部长期记忆中检索相关信息，并整合到短期记忆中（manus的”知识“模块）
  - 反思与决策层：agent引导LLM对过去的记忆进行反思，agent会分析的自己的行为和结果，从中提取高层次的见解，作为新的知识并入到长期记忆

###### ②生成式建模

- 是什么：

###### ③专用神经网络工具