#### Multi-Relational Graph Attention Network for Social Relationship Inference from Human Mobility Data - 从人类流动数据推断社会关系的多关系图注意网络

> code：https://github.com/qinguangming1999/MRGAN_IJCAI

##### 干了什么工作

提出了一个模型，可以从人类的**移动数据**中**推断社会关系**

##### 现有推断社会关系的方法的缺陷

- 现有方法：基于图（graph）推断社交关系
- 缺陷
  - 通常只考虑直接关系
  - 忽略了**移动模式**以及**间接关系**

- 该模型的优势
  - 明确建模直接和间接关系
  - GAT捕捉不同影响和重要程度

##### 提出该方法的背景

社交媒体的位置服务（定位），生成大量用户移动的时空数据，这些数据可以用来推断社交关系、服务于推荐系统等

##### 这个模型的功能

- 建模直接关系（eg好友关系、见面关系）以及间接关系
  - 好友关系：社交网络中两顶点相连
  - 见面关系：双方在同一地点、同一时间阈值中有签到
  - 间接关系：指用户通过中间节点建立的联系
    - 通过**同一个兴趣点/地点**作为中介产生联系（比如经常去同一个咖啡馆）==（PP）==
    - 通过**一对地点**，产生的联系，这一对地点通常是被选择搭配的地点，比如去图书馆前先去咖啡店买咖啡，所以假设有两个用户：A、B，即使A只去图书馆，B只去咖啡店，但A与B就会因为这条图书馆-咖啡店的线路产生联系==（CP）==
- 使用两个Attention
  - 影响注意力
  - 跨关系注意力

##### 推断社会关系方法的发展历史

- 早期：分析用户移动轨迹、见面时间地点
- 基于网络表征学习和图深度学习：随机游走、图嵌入、GCN、超图等
- 近期：去除移动数据中的噪声边来提供推断关系的准确性

##### 问题的定义

- 给定用户移动轨迹和部分已知关系，预测用户对之间是否存在社会关系
- 相关概念
  - 签到记录：用户u在时间t访问POI组成的记录
  - 移动轨迹：用户u的一系列签到记录
  - 见面事件：两个用户在时间阈值t'内在同一地点p均存在签到记录
  - 见面频率：两用户之间所有见面事件总次数

##### 模型工作流程

> 主要流程
>
> 1.构建异构移动图
>
> 2.拆分成多种关系子图
>
> 3.在每种关系上编码邻居影响（用**关系内注意力**学习邻居影响）
>
> 4.跨关系聚合嵌入（用**跨关系注意力**聚合用户多关系表示）
>
> 5.下游任务预测

- 图1：异构移动图，异构：两种类型的节点（User，POI），多种边（图左下部分）
- 图2：对每个关系（好友/见面/PP/CP），拆分为4个关系子图**（每个子图都可以单独的学习用户表示）**
- 图3：每个关系子图中：以目标用户为中心，聚合其邻居节点，Attention学习邻居对目标节点的不同权重影响
  - 核心：每个关系子图中，用户的表示都不同
  - 所以会计算4次Attention（每种关系计算1次），得到4个**relation-specific embedding**
- 图4：把上一次Attention得到的4个嵌入再输入到跨关系Attention，融合这4个嵌入为1个，最终经Decoder输出结果

> **通过一个跨关系的注意力机制，动态地融合这些表示，以获得一个能够全面捕捉用户多种移动交互模式的最终嵌入** 

![image-20250918104125681](https://raw.githubusercontent.com/naplatte/Pictures/main/95594ee90ebd4a5a5bb3b7c9a8d7dc0c.png)



#### Graph Attention Network with High-Order Neighbor Information Propagation for Social Recommendation - 具有高阶邻居信息的图注意力网络社交推荐传播

##### 需要解决什么问题 + 之前方法不足

- 服务于：社交推荐系统

- GNN、GCN、GAT缺陷
  - 容易过平滑：图卷积数增大时，不同节点的表示会趋近相似 -> 不能很好的利用**高阶邻居信息**
  - 需要手动定义元路径

##### 为什么这个模型好

- 可以利用高阶邻居信息
- 融合序列依赖（LSTM）与非序列依赖（Attention）

##### 模型内容⭐

1. 高阶路径采样：通过一个通用的异构图游走框架，从社交网络中为每个用户和物品节点，采样出高阶路径实例
   - 不依赖手动定义的元路径，通过**随机游走**的方式探索邻居关系
2. **路径实例学习表示**✨：即对每个路径实例编码，**将路径实例视为一个序列和一个集合**，并设计一个门控机制融合这两种视图
   - **序列依赖捕捉**：LSTM存储路径节点的顺序信息，捕捉序列化的依赖关系
   - **非序列依赖捕捉**：一个特殊的Attention处理
   - **门控机制**：融合二者信息，合二为一
3. 路径实例聚合：将一个节点所有路径的信息聚合起来，也是用一层**注意力网络**，形成该节点的最终嵌入
   - 注意力：哪些路径重要，哪些路径不重要

4. 预测：计算用户对

![image-20250918095922187](https://raw.githubusercontent.com/naplatte/Pictures/main/b318395de5bdbbf4f68f1023b1e8347a.png)

