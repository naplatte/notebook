```markdown
需要补的内容

- 可变参数模板 ✅️
- 可变参数模板的应用 - 完美转发✅️
template<typename T, typename... Args>
T* newElement(Args&&... args)
{
    T* p = nullptr;
    // 根据元素大小选取合适的内存池分配内存
    if ((p = reinterpret_cast<T*>(HashBucket::useMemory(sizeof(T)))) != nullptr)
        // 在分配的内存上构造对象
        new(p) T(std::forward<Args>(args)...);

    return p;
}

- 工厂+管理者模式 ✅️
HashBucket类是MemoryPool类的工厂+管理者，创建其单例对象

- Slot*类型对象比大小问题 (C++的指针运算 - 算术运算、比较运算)
if (curSlot >= lastSlot_)

- std::memory_order✅️
- CAS指令✅️
- 强转✅️
- 测试代码中的多线程创建
```



### 1.相关理论内容

#### 1.1 内存池是什么

- 是一种**预分配内存并进行重复利用的技术**，通过**减少频繁的动态内存分配与释放操作**，提高程序运行效率
- 因为申请内存要涉及到**系统调用**，os由用户态 → 内核态，无疑会增大开销
- 内存池通常**预先分配一块较大的空间**，将其划分为多个小块，每次需要分配内存时直接从这块大的空间中分配（通过预分配和一些管理逻辑提高内存分配和释放效率）

#### 1.2 内存池的作用

1. 首先就是上文提到的减少频繁的动态内存分配与释放，提高程序运行效率（降低系统调用频率）
2. 减少外碎片问题：频繁的`malloc/free`会使内存中大的空闲块越来越少
3. 分配时间更可靠：内存池可以使分配和释放操作的**耗时**更加可控和稳定，适合**实时OS**

#### 1.3 内存池应用场景

- 游戏开发：大量小对象（粒子、子弹等）动态分配和释放很频繁
- 网络编程：大量请求和响应对象的频繁创建与销毁
- 内存管理库：`vector、deque`等容器内部使用内存池优化分配性能

- 实时OS：追求分配释放内存的稳定性
- 高性能计算：高性能计算程序中，频繁分配释放内存影响整个程序性能
- 服务器开发：web服务器 管理大量连接和请求

#### 1.4 内存池的缺点

- 初始内存占用：内存池需要分配较大内存作为初始内存，可能会浪费一些内存
- 复杂：使用内存池分配内存比直接使用new/malloc更复杂
- 不适合大型对象：因为**内存池设计的初衷就是针对频繁分配的小对象**，而大型对象往往占用空间大，且分配不频繁

### 2. v1版本	

#### 2.1 序

<img src="https://raw.githubusercontent.com/naplatte/Pictures/main/83442d0abb07ef8a78ad3c4f6e2bb863.png" alt="image-20251023162629002" style="zoom:67%;" />	

- 看懂架构

  - 维护一个哈希桶，每一项都对应一个MemoryPool，每个MemoryPool的总大小都是相同的（哈希桶管理多个内存池）
  - 每个内存池中有若干个**内存块**，**块与块之间通过链表连接起来**
    - 各内存池的块都是相同的，`MemoryPool`类中的`firstBlock_`指向内存池管理的**首个内存块**（实际指向的是首个内存块的第一个槽）
    - 每个内存块内有若干个**槽**，对于**同一个内存池内，槽的大小是相同的**
    - 不同内存池之间，槽的大小是不同的，最小为8B，往上以8的倍数递增，**最多为512B**
  - 释放对象时，内存归还给内存池，此时内存池不会将内存还给系统，而是**将指向该内存的指针前插到链表`freeSlot_`中**（避免频繁申请/归还资源），之后每次申请内存时，就先在`freeSlot_`链表中找
  - 如果`freeSlot_`为空，则将`curSlot`所指的内存分配出去（`curSlot_`指向当前未被使用过且将要分配出去的下一个槽）
  - 若block中的空闲槽用完，则向OS申请新的block

- 每个MemoryPool的内部结构

  - 每个槽按**链表**的形式存储
  - 需要的数据：

  ```cpp
  int BlockSize_; // 内存块大小
  int SlotSize_; // 槽大小
  Slot* firstBlock_; // 指向内存池管理的首个内存块
  Slot* curSlot; // 指向当前未被使用过的槽（将要分配出去的下一个槽）
  std::atomic<Slot*> freeList_; // 指向空闲的槽（被使用后又被释放）
  Slot* lastSlot_; // 当前内存块中最后能够存放元素的位置标识（超过该位置需要申请新内存块）
  std::mutex mutexForBlock_;	
  ```

#### 2.2 由思路游龙到代码

> 跟着思路，想到啥写啥

- 为什么会有哈希桶：因为内存池有很多个，写的是内存池，而不是1个内存池，每个内存池虽然总大小一样，里面内存块的大小一样，但内存池与内存池之间，内部槽大小是不一样的，因此当用户申请空间时，我们应选择合适的内存池去分配（实际是选择合适的槽对应的内存池），所以需要有一个东西去管理这些内存池，即是hashbucket

- 为什么叫哈希桶：哈希桶的核心功能就是根据用户需要的内存，选择一个拥有合适槽的内存池，这个过程就是一个将**内存大小映射到对应MemoryPool实例**的过程，这个映射的过程类似哈希函数key->value的过程。因为管理的是一个memoryPool数组（每一项都是内存池类的实例），每个memoryPool就像一个桶一样

- 哈希桶是怎么管理MemoryPool的

  - 管理内存池的创建与删除：类似工厂模式调用MemoryPool的构造，删除时将内存池中的内存块全部operator delete掉
  - 用户内存的申请与释放：需要有向内存池申请和释放内存的接口

- 在哈希桶的管理下，MemoryPool需要完成什么工作

  - （构造/析构）

  - 提供分配/释放内存的接口给哈希桶，分配就涉及到向OS申请新的块，分配与释放也涉及着下面的freelist，这也是自定义内存池的核心
  - freelist：保存之前被使用过，但已被释放的内存块（不直接给OS，先自己收着）——对应就会有cur内存块入队出队的问题

### 3. v2版本

#### 3.1 三层内存池概述

> 内存池通过分层缓存架构来管理内存，主要包括以下三层

1. 线程本地缓存（ThreadCache）
   - 每个线程独立的内存缓存（这点有些和认知不同，认知里一个进程的所有线程都是共享进程的内存的，实际上也是这样的，只是为每个线程建立了内存缓存）
   - 无锁操作 - 快速分配和释放
   - 减少线程间竞争，提高并发性能
2. 中心缓存（CentralCache）
   - 管理多个线程共享的内存块
   - 通过自旋锁保护，确保线程安全
   - 批量从页缓存中获取内存，分配给线程缓存
3. 页缓存（PageCache）
   - 从OS获取大的内存块
   - 将大块内存切为小块，供中心线程使用
   - 负责内存的回收和再利用

<img src="https://raw.githubusercontent.com/naplatte/Pictures/main/0b5fa34099c1ac2573857d88e20546e6.png" alt="image-20251104185019088"  />	

#### 3.2 过思路

##### 3.2.1 首先是线程本地缓存

- 这一层的任务
  - 为线程分配内存（检查本地是否有）、回收内存
  - 与中心缓存交互（没内存时向中心缓存申请、内存过多时交换一部分给中心缓存）
- 两个关键数据结构
  - `std::array<void*,FREE_LIST_SIZE> freeList_; // 长度为 FREE_LIST_SIZE 的定长数组，每个元素都是 void* 指针`
  - `std::array<size_t,FREE_LIST_SIZE> freeListSize_; // 长度为FREE_LIST_SIZE的定长数组，每个元素都是size_`

- 

